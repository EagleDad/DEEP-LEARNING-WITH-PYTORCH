{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# <font style=\"color:blue\">Check Training Pipeline<\/font>\n",
                "\n",
                "\n",
                "In one of our videos under `Training Deep Networks`, we have discussed some points regarding the Training Pipeline.   \n",
                "Following are the points written in code. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "import os\n",
                "import torch\n",
                "import numpy as np\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### <font style=\"color:blue\">1. Fix random seed<\/font>\n",
                "\n",
                "We deal with only one numeric computational library ie Pytorch. So we'll set its random seed.\n",
                "Following is the code to do so."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": [
                "torch.manual_seed(0)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### <font style=\"color:blue\">2. Use a simple baseline model<\/font>\n",
                "\n",
                "\n",
                "Throughout this notebook we will discuss the 10-points by using a simple dataset. This dataset is a small subset from the Caltech-101 data which can be downloaded from here.\n",
                "https:\/\/data.caltech.edu\/records\/mzrjq-6wc02\n",
                "\n",
                "This subset data spans across 4 classes ie [chandelier, watch, laptop, motorbike] with roughly 400 images in total.\n",
                "\n",
                "We will use a simple Image Classification network which consists of a few Conv and Linear layers. The input size will be (3, 160, 160) and the output nodes will be 4.\n",
                "\n",
                "Let's define a simple model in the following block."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "class Net(nn.Module):\n",
                "    def __init__(self,n_classes):\n",
                "        super(Net, self).__init__()\n",
                "        self.conv1 = nn.Conv2d(3, 32, 3, 1)\n",
                "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
                "        self.conv3 = nn.Conv2d(64, 32, 3, 1)\n",
                "        self.conv4 = nn.Conv2d(32, 32, 3, 1)\n",
                "        self.fc1 = nn.Linear(10368, 2048)\n",
                "        self.fc2 = nn.Linear(2048,128)\n",
                "        self.fc3 = nn.Linear(128, n_classes)\n",
                "\n",
                "    def forward(self, x):\n",
                "        x = self.conv1(x)\n",
                "        x = F.relu(x)\n",
                "        x = self.conv2(x)\n",
                "        x = F.relu(x)\n",
                "        x = F.max_pool2d(x, 2)\n",
                "        x = self.conv3(x)\n",
                "        x = F.relu(x)\n",
                "        x = F.max_pool2d(x, 2)\n",
                "        \n",
                "        x = self.conv4(x)\n",
                "        x = F.relu(x)\n",
                "        x = F.max_pool2d(x, 2)\n",
                "        \n",
                "        x = torch.flatten(x, 1)\n",
                "        x = self.fc1(x)\n",
                "        x = F.relu(x)\n",
                "        x = self.fc2(x)\n",
                "        x = F.relu(x)\n",
                "        x = self.fc3(x)\n",
                "        return x"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### <font style=\"color:blue\">3. Turn-off  data augmentation<\/font>\n",
                "\n",
                "Sometimes, we use augmentation techniques such as random-rotation, adding small noise, translating the image etc.\n",
                "When we are ensuring reproducibility, we do not need such techniques. We shall only use Resizing, Cropping and Normalization since they are deterministic.\n",
                "\n",
                "The images in the data span various sizes, therefore we need to fix the size to `(160,160)` since this is the size our model expects as input.\n",
                "\n",
                "We will also need a generator which will give us the required batch of images as we train. Pytorch provides a good handle for this as well.\n",
                "Don't worry if you don't understand the below code. It will be taught in the upcoming lectures.\n",
                "As of now, you just need to know that the following code does the preprocessing step (without any augmentation) and gives us the data-generator for feeding to the neural-network.\n",
                "\n",
                "Following is the code."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "from torchvision import datasets, transforms\n",
                "\n",
                "preprocess = transforms.Compose([transforms.Resize((196,196)),transforms.CenterCrop((160,160)),\n",
                "                                 transforms.ToTensor()])\n",
                "\n",
                "data_root = \"..\/resource\/lib\/publicdata\/caltech_subset\"\n",
                "    \n",
                "train_data_path = os.path.join(data_root, 'train')\n",
                "test_data_path = os.path.join(data_root, 'test')\n",
                "\n",
                "\n",
                "train_loader = torch.utils.data.DataLoader(\n",
                "    datasets.ImageFolder(root=train_data_path, transform=preprocess),\n",
                "    batch_size=16,\n",
                "    shuffle=True,\n",
                "    num_workers=2)\n",
                "\n",
                "\n",
                "\n",
                "test_loader = torch.utils.data.DataLoader(\n",
                "    datasets.ImageFolder(root=test_data_path, transform=preprocess),\n",
                "    batch_size=16,\n",
                "    shuffle=False,\n",
                "    num_workers=2\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### <font style=\"color:blue\">4. Visualize input data before it goes inside the network<\/font>\n",
                "\n",
                "This step ensures that the input goes inside the network as expected. It's just a sanity-check.\n",
                "We can use image-visualizing libraries such as `PIL`, `OpenCV` or `Matplotlib` to achieve this process.\n",
                "We will use the `train_loader` to give us the batch of images and pick some samples and plot them.\n",
                "Please consider omitting the `transforms.Normalize()` if you are using it during the pre-processing step. Because, if normalization is present then the pixel values would not be in the range of `[0-255]`.\n",
                "\n",
                "Following is the code to visualize some of the images."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "\n",
                "plt.rcParams[\"figure.figsize\"] = (16, 10)\n",
                "plt.figure\n",
                "for images, labels in train_loader:\n",
                "    for i in range(len(labels)):\n",
                "        plt.subplot(4, 4, i+1)\n",
                "        img = transforms.functional.to_pil_image(images[i])\n",
                "        plt.imshow(img)\n",
                "        plt.gca().set_title('Target: {0}'.format(labels[i]))\n",
                "        plt.axis('off')\n",
                "    plt.show()\n",
                "    break"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### <font style=\"color:blue\">5. Check initial loss and accuracy.<\/font>\n",
                "\n",
                "We will verify if a model is initialized randomly, then the initial loss must be around `log(num_classes)` and the initial acuracy be around `1\/num_classes` \n",
                "\n",
                "\n",
                "We shall create a class `CheckInitLossAndAccuracy` for verifying the 5th point by calculating the loss and accuracy.\n",
                "We will need the following arguments:-\n",
                "1. A randomly initialized model.\n",
                "2. A batch of input.\n",
                "3. A batch of  target classes.\n",
                "4. Number of classes.\n",
                "\n",
                "\n",
                "The class has two methods called `verify_init_loss` which verifies if the intial loss is around `log(num_classes)` and `verify_init_accuracy` which verifes if the initial accuracy is around `1\/num_classes`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "class CheckInitLossAndAccuracy():\n",
                "    def __init__(self, net, x, num_classes, target = None):\n",
                "        self.net = net\n",
                "        self.x = x\n",
                "        self.num_classes = num_classes\n",
                "        self.criterion = nn.CrossEntropyLoss()\n",
                "        self.batch_size = self.x.size()[0]\n",
                "        if target is None:\n",
                "            self.target = torch.randint(0, self.num_classes, size=(self.batch_size,))\n",
                "        else:\n",
                "            self.target = target\n",
                "        self.logits = self.net(self.x)\n",
                "\n",
                "    def verify_init_loss(self):\n",
                "        loss = self.criterion(self.logits, self.target)\n",
                "        print(\"Expected loss is \", np.log(self.num_classes))\n",
                "        print(\"Inferred loss is \", loss.item())\n",
                "        return None\n",
                "\n",
                "    def verify_init_accuracy(self):\n",
                "        predictions = torch.argmax(F.softmax(self.logits, dim=1), axis=1)\n",
                "        accuracy = accuracy_score(self.target, predictions.detach())\n",
                "        print(\"Expected accuracy is \", 1 \/ self.num_classes)\n",
                "        print(\"Inferred accuracy is \", accuracy)\n",
                "        return None\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.metrics import accuracy_score\n",
                "\n",
                "n = 4\n",
                "x, target = next(iter(train_loader))\n",
                "\n",
                "print(\"num classes are \", n)\n",
                "model = Net(n)\n",
                "check = CheckInitLossAndAccuracy(model, x, n, target)\n",
                "check.verify_init_loss()\n",
                "check.verify_init_accuracy()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                " Looking at the numbers, they are approximately equal.!"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### <font style=\"color:blue\">6. Check if loss goes down every epoch.<\/font>\n",
                "\n",
                "In-order to check if the loss goes down every epoch, we need to set-up the typical training procedure for a Neural Network. We also need to store the loss values in a list or an array, so that it can be vizualized later after training gets over.\n",
                "\n",
                "Following is the code to do so."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch.optim as optim\n",
                "\n",
                "num_classes = 4\n",
                "model1 = Net(num_classes)\n",
                "criterion = nn.CrossEntropyLoss()\n",
                "optimizer = optim.SGD(model1.parameters(), lr=0.001, momentum = 0.9)\n",
                "\n",
                "\n",
                "loss_list = []\n",
                "num_epochs = 10\n",
                "for epoch in range(num_epochs): \n",
                "    per_epoch_loss= 0\n",
                "    for i, data in enumerate(train_loader): \n",
                "        optimizer.zero_grad()\n",
                "        x, target = data\n",
                "        logits = model1(x)\n",
                "        loss = criterion(logits, target)\n",
                "        temp_loss = loss.item()\n",
                "        per_epoch_loss+=temp_loss\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "        \n",
                "    per_epoch_avg_loss = per_epoch_loss\/(i+1)\n",
                "    loss_list.append(per_epoch_avg_loss)\n",
                "    print(\"Loss at epoch {0} = {1}\".format(epoch+1, per_epoch_avg_loss ))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We have kept track of the `loss` at every epoch in the `loss_list`, let's use them to plot the loss-curve."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize = (6,4))\n",
                "plt.plot(loss_list)\n",
                "plt.title('model loss')\n",
                "plt.ylabel('loss')\n",
                "plt.xlabel('epoch')\n",
                "plt.xticks(np.arange(0,10))\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We see from the loss-curve that the loss is indeed dropping down."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### <font style=\"color:blue\">7. Forward the same batch for multiple interations and check if loss drops down to 0 <\/font>\n",
                "\n",
                "We will use the same code mentioned above, except that we wont iterate over the batch, but forward the same batch and monitor the loss. Note that we shall use the `Adam` optimizer rather than the `SGD` due to the fact that `SGD`  updates the parameters very slowly and skips the minima easily. \n",
                "Since we want to verify that the loss approaches zero and does not skip it, we want a suitable optimizer, and one such is `Adam` .\n",
                "\n",
                "Following is the code."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": [
                "import torch.optim as optim\n",
                "\n",
                "num_classes = 4\n",
                "model2 = Net(num_classes)\n",
                "criterion = nn.CrossEntropyLoss()\n",
                "optimizer = optim.Adam(model2.parameters(), lr=0.001)\n",
                "\n",
                "x, target = next(iter(train_loader))\n",
                "\n",
                "\n",
                "loss_list = []\n",
                "num_iters = 25\n",
                "for i in range(num_iters): \n",
                "    optimizer.zero_grad()\n",
                "    logits = model2(x)\n",
                "    loss = criterion(logits, target)\n",
                "    temp_loss = loss.item()\n",
                "    loss.backward()\n",
                "    optimizer.step()\n",
                "    loss_list.append(temp_loss)\n",
                "    print(\"Loss at iteration-{} is {}\".format(i+1,temp_loss))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Let's plot the loss curve.\n",
                "\n",
                "plt.figure(figsize = (6,4))\n",
                "plt.plot(loss_list)\n",
                "plt.title('model loss')\n",
                "plt.ylabel('loss')\n",
                "plt.xlabel('epoch')\n",
                "plt.xticks(np.arange(0,i+1))\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### <font style=\"color:blue\">8. Forward-pass a zero input and check if loss is high.<\/font>\n",
                "\n",
                "For this, we will use a model trained in 6th point ie `model1` and look at the loss.\n",
                "The `input` or `x` to this model will be Tensors of zeros and the `target` will be a set of random numbers between `0` and `3`.    \n",
                "We got a final loss of `1.3643` at the 10th-epoch in `section-6` , so we expect that the randomized input shall produce a much higher loss than this."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": [
                "criterion = nn.CrossEntropyLoss()\n",
                "\n",
                "x = torch.zeros(size = (16,3,160,160))\n",
                "target = torch.randint(0,4,size = (16,))\n",
                "logits = model1(x)\n",
                "\n",
                "loss = criterion(logits,target)\n",
                "print(\"Loss with zero-valued input is \", loss.item())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### <font style=\"color:blue\">9. Calculate the loss on entire test-set <\/font>\n",
                "\n",
                "For this, we already have a generator called the `test_loader`. Everytime we want to test our model's performance, we will use this generator.\n",
                "The following code will calculate the test-loss on entire test-set every 2 epochs. \n",
                "Note that we can calculate the test-loss at every epoch as well, it really depends on the user as to how frequently the loss needs to be logged.\n",
                "\n",
                "We will use the same code mentioned in 6th point but with a few extra lines of code for calculating the test-loss.\n",
                "Following is the code."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch.optim as optim\n",
                "\n",
                "num_classes = 4\n",
                "model3 = Net(num_classes)\n",
                "criterion = nn.CrossEntropyLoss()\n",
                "optimizer = optim.SGD(model3.parameters(), lr=0.001, momentum=0.9)\n",
                "\n",
                "\n",
                "loss_list = []\n",
                "num_epochs = 10\n",
                "for epoch in range(num_epochs): \n",
                "    per_epoch_loss= 0\n",
                "    for i, data in enumerate(train_loader): \n",
                "        optimizer.zero_grad()\n",
                "        x, target = data\n",
                "        model3.train()\n",
                "        logits = model3(x)\n",
                "        loss = criterion(logits, target)\n",
                "        temp_loss = loss.item()\n",
                "        per_epoch_loss+=temp_loss\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "    per_epoch_avg_loss = per_epoch_loss\/(i+1)\n",
                "    loss_list.append(per_epoch_avg_loss)\n",
                "    print(\"Traning loss at epoch {} = {}\".format(epoch+1, per_epoch_avg_loss ))\n",
                "    \n",
                "    if(epoch+1)%2==0:\n",
                "        total_test_loss = 0\n",
                "        with torch.no_grad():\n",
                "            model3.eval()\n",
                "            for j, test_data in enumerate(test_loader):\n",
                "                test_x, test_target = test_data\n",
                "                test_logits = model3(test_x)\n",
                "                test_loss = criterion(test_logits, test_target)\n",
                "                total_test_loss+= test_loss.item()\n",
                "            print(\"Test loss at epoch {} = {}\".format(epoch+1, total_test_loss\/(j+1)))\n",
                "            "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### <font style=\"color:blue\">10. Check dimensions using Backprop<\/font>\n",
                "\n",
                "Let's break-down the points discussed in the video with a concrete example.\n",
                "\n",
                "1. Consider a simple network with just a few Conv and Linear layers whose input is (1,28,28) and output is 10 nodes.\n",
                "\n",
                "2. We will consider the batch-size to be 25. Therefore, input size will be (25,1,28,28) and the output size will be (25,10).\n",
                "\n",
                "3. Once we have got the output, we plug this output inside the Loss function to get a loss. Typically, this loss is just one element (a scalar), which is either summed or averaged over the 25 loss-values. However, we can get the un-summed and un-averaged loss-values by passing `reduction='none'` when instantiating `nn.CrossEntropyLoss()`. \n",
                "Now, if we evaluate the loss, it would not be a scalar, but a vector of 25 entries where each entry corresponds to the loss for each image in the batch.\n",
                "\n",
                "4. As discussed in the video, we need to keep only one entry ( eg. 11th entry ) in this 25-d loss-vector intact, and set all the rest 24 entries to zero. And then calculate the gradients via backpropogation from this modified loss.\n",
                "\n",
                "5. Now that we have backpropogated, its gradients can be accessed. At this point, note that the gradients should be of size (25, 784, 10), where each entry in the first dimension corresponds to the gradients for each image.\n",
                "\n",
                "According to our claim, if the dimensions are right, then the gradients in the 11th entry will be non-zero, and the gradients in the rest will be zero.\n",
                "However, instead of checking if the entries are zero, we could just sum up the gradients along the batch (first) dimension and look at the resulting 25 numbers. We will notice that the index with the highest number will be 11 indicating that the gradients at the 11th entry are non-zero.\n",
                "\n",
                "If the dimensions are not right, then the index will not be 11.\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**NOTE**     \n",
                "In order to verify this claim using code, there is a small bottleneck.   \n",
                "Pytorch expects `loss` to be scalar, it will throw an error if a Tensor ( in our case, if a 25-d vector ) is passed.  \n",
                "And due to this, the gradients which we can access after `loss.backward()` will be of size `(784,10)` and not `(25,784,10)`, ie the gradients will be calculated from the `sum` or `average` over the 25 entries of loss values.     \n",
                "But, no worries, we will show you a work-around for this."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "   \n",
                "This work-around is carried out in two steps\n",
                "\n",
                "STEP-1 `get_batched_gradients_metric`\n",
                "\n",
                "1. Follow the same steps upto the 4th point, ie keeping only the 11th entry intact, and set the rest entries to 0, and    SUM-THEM-UP. Now that we have a Scalar, and we can easily backprop this. \n",
                "2. After backprop, the gradients are expected to be of size `(784,10)`. However, we are not sure if these gradients really belonged to the 11th image or not. So, we need to perform one more step to verify if these gradients did really belong to the 11th image or not.\n",
                "\n",
                "3. As a side note, let's not look at the whole set of gradients, instead, we'll look at its absolute-sum, it will be much easier to compare. \n",
                "\n",
                "\n",
                "STEP-2 (as a verification method for step-1 ) `get_individual_gradients_metric`\n",
                "\n",
                "1. Follow the same steps upto the 4th point, ie keeping only the 11th entry intact, and set the rest entries to 0.\n",
                "Instead of summing the Loss-vector and bringing it to a Scalar, we will do it in an iterative-way over the whole batch.\n",
                "2. For each image in the batch, we backprop with its corresponding loss. This essentially means that, only the 11th image will have a non-zero loss, because the rest loss entries will be zero.   We will also keep track of the absolute sum of gradients for each image.\n",
                "4. Once the iteration on the batch is over, we will have 25 such gradient-sums. \n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "In step-2, we should notice that only the gradient-sum at the 11th entry will be non-zero, rest will be zero.\n",
                "Also, this non-zero value must be exactly equal to the number we get in step-1.\n",
                "Thus indicating that only the 11th entry over the batch has gradients, inturn indicating that the dimensions are correct."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "\n",
                "We will use the class `Check_dims_via_backprop` for verifying the 10th point. The class expects the following parameters:-\n",
                "1. Input batch\n",
                "2. The Network-class\n",
                "3. Target batch\n",
                "4. A random number indication which image in the batch we want to experiment with.\n",
                "\n",
                "As mentioned above, we have to execute two steps to claim the statement mentioned above.\n",
                "The method `get_batched_gradients_metric()` will give us the gradient-sum as mentioned in STEP-1.\n",
                "The method `get_individual_gradients_metric()` will give us the gradient-sum for each image as mentioned in STEP-2"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "class CheckDimsViaBackprop():\n",
                "    def __init__(self, net_class, x, num_classes, target=None, which_sample=11):\n",
                "        self.first_model = None\n",
                "        self.net_class = net_class\n",
                "        self.x = x\n",
                "        self.num_classes = num_classes\n",
                "        self.batch_size = self.x.size()[0]\n",
                "        self.which_sample = which_sample\n",
                "        if target is None:\n",
                "            self.target = torch.randint(0, self.num_classes, size=(self.batch_size,))\n",
                "        else:\n",
                "            self.target = target\n",
                "\n",
                "    def get_batched_gradients_metric(self):\n",
                "        first_model = self.net_class(self.num_classes)\n",
                "        self.first_model = first_model\n",
                "        criterion = nn.CrossEntropyLoss(reduction='none')\n",
                "\n",
                "        logits = first_model(self.x)\n",
                "        loss = criterion(logits, self.target)\n",
                "\n",
                "        mask = torch.zeros_like(loss)\n",
                "        mask[self.which_sample] = 1\n",
                "        loss *= mask\n",
                "        loss = loss.sum()\n",
                "        loss.backward()\n",
                "        grad_metric = abs(sum([p.grad.numpy().sum() for p in list(first_model.parameters())]))\n",
                "        print(\"Batched Gradient metric =  \", grad_metric)\n",
                "        return None\n",
                "\n",
                "    def get_individual_gradients_metric(self):\n",
                "        second_model = self.net_class(self.num_classes)\n",
                "        second_model.load_state_dict(self.first_model.state_dict())\n",
                "\n",
                "        criterion = nn.CrossEntropyLoss(reduction='none')\n",
                "        logits = second_model(self.x)\n",
                "        loss = criterion(logits, self.target)\n",
                "\n",
                "        mask = torch.zeros_like(loss)\n",
                "        mask[self.which_sample] = 1\n",
                "        loss *= mask\n",
                "        temp_loss = loss.clone()\n",
                "\n",
                "        for i in range(len(temp_loss)):\n",
                "            second_model.zero_grad()\n",
                "            temp_img = self.x[i, ...]\n",
                "            op = second_model(torch.unsqueeze(temp_img, 0))\n",
                "            temp_target = torch.Tensor([self.target[i]]).long()\n",
                "            loss = temp_loss[i]\n",
                "            loss.backward(retain_graph=True)\n",
                "            grads = [p.grad.numpy().sum() for p in list(second_model.parameters())]\n",
                "            grad_metric = abs(sum(grads))\n",
                "            if grad_metric > 0:\n",
                "                print(\"Gradient metric at sample {} =  \".format(i), grad_metric)\n",
                "        return None\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Following is an example of using the above class.\n",
                "As usual, we will grab a batch from the `train_loader`, and we shall experiment with the image at the 11th entry, just to remain consistent with the explanation."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [],
            "source": [
                "num_classes  = 4\n",
                "\n",
                "x, target = next(iter(train_loader))\n",
                "\n",
                "\n",
                "which_one = 11\n",
                "check2 = CheckDimsViaBackprop(Net, x, num_classes, target, which_one)# NOTE - this will expect the nn.Module class, not the nn.Module object..!!\n",
                "assert which_one < x.size()[0]\n",
                "\n",
                "check2.get_batched_gradients_metric()\n",
                "check2.get_individual_gradients_metric()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The gradient-sum we got from STEP-1 is present at the 11th index, clearly indicating that the dimensions are right.!"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "References\n",
                "1. https:\/\/pytorch.org\/tutorials\/beginner\/blitz\/cifar10_tutorial.html"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.8",
            "language": "python",
            "name": "python38"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text\/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}