{"cells":[{"cell_type":"markdown","metadata":{"id":"cebX2ljguESC"},"source":["# <font color='blue'> ONNX - Open Neural Network Exchange</font>\n"]},{"cell_type":"markdown","metadata":{"id":"86kAdCpUuESI"},"source":["<img src=\"https://www.learnopencv.com/wp-content/uploads/2020/09/c3-w15-onnx.png\" height=\"500\">\n","\n","---\n","\n","ONNX, as the name says, is a platform for exchanging the formats `(.pth(Pytorch), .pb(TensorFlow), etc.)` of Neural Networks.\n","\n","**Why do we need ONNX?**\n","\n","Often, the training environment (Python) is different from the production environment (Java, C#, etc.), and these models need to be deployed.\n","\n","Since we have trained the models in either any of the Deep Learning frameworks,  we somehow want to port this model for serving. And this is where ONNX appears to be pretty handy.\n","\n","\n","Sometimes, we might also need to switch the model between frameworks ie, from `Pytorch to MXNET` or from `Keras to Pytorch`, etc., and ONNX can help us here too.\n","\n","We also need to note that every framework has its way of storing the weights ie, Keras saves the model-weights as a `.h5` file, Pytorch just stores the weights in a `.pth` file, so we need a way to store the weights such that all the frameworks can recognize it.\n","\n","## <font color='blue'>Installations</font>\n","\n","Before we start, we need to install the required dependencies. So let's start with installation."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YOhsRGD2uESO","executionInfo":{"status":"ok","timestamp":1756301446759,"user_tz":-120,"elapsed":26179,"user":{"displayName":"Dirk Adler","userId":"10888330956412535296"}},"outputId":"01e9cde6-a6da-47cf-e59a-3114363c918f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting onnx\n","  Downloading onnx-1.19.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (7.0 kB)\n","Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.12/dist-packages (from onnx) (2.0.2)\n","Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.12/dist-packages (from onnx) (5.29.5)\n","Requirement already satisfied: typing_extensions>=4.7.1 in /usr/local/lib/python3.12/dist-packages (from onnx) (4.14.1)\n","Requirement already satisfied: ml_dtypes in /usr/local/lib/python3.12/dist-packages (from onnx) (0.5.3)\n","Downloading onnx-1.19.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (18.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m100.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: onnx\n","Successfully installed onnx-1.19.0\n","Collecting onnxruntime\n","  Downloading onnxruntime-1.22.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n","Collecting coloredlogs (from onnxruntime)\n","  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (25.2.10)\n","Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (2.0.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (25.0)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (5.29.5)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (1.13.3)\n","Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n","  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime) (1.3.0)\n","Downloading onnxruntime-1.22.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m112.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: humanfriendly, coloredlogs, onnxruntime\n","Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.22.1\n","Collecting onnx2keras\n","  Downloading onnx2keras-0.0.24.tar.gz (20 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (from onnx2keras) (2.19.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from onnx2keras) (2.0.2)\n","Requirement already satisfied: onnx in /usr/local/lib/python3.12/dist-packages (from onnx2keras) (1.19.0)\n","Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.12/dist-packages (from onnx->onnx2keras) (5.29.5)\n","Requirement already satisfied: typing_extensions>=4.7.1 in /usr/local/lib/python3.12/dist-packages (from onnx->onnx2keras) (4.14.1)\n","Requirement already satisfied: ml_dtypes in /usr/local/lib/python3.12/dist-packages (from onnx->onnx2keras) (0.5.3)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->onnx2keras) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->onnx2keras) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow->onnx2keras) (25.2.10)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow->onnx2keras) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow->onnx2keras) (0.2.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->onnx2keras) (18.1.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow->onnx2keras) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow->onnx2keras) (25.0)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->onnx2keras) (2.32.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow->onnx2keras) (75.2.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->onnx2keras) (1.17.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->onnx2keras) (3.1.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->onnx2keras) (1.17.3)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow->onnx2keras) (1.74.0)\n","Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->onnx2keras) (2.19.0)\n","Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->onnx2keras) (3.10.0)\n","Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->onnx2keras) (3.14.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow->onnx2keras) (0.45.1)\n","Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow->onnx2keras) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow->onnx2keras) (0.1.0)\n","Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow->onnx2keras) (0.17.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow->onnx2keras) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow->onnx2keras) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow->onnx2keras) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow->onnx2keras) (2025.8.3)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow->onnx2keras) (3.8.2)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow->onnx2keras) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow->onnx2keras) (3.1.3)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow->onnx2keras) (3.0.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow->onnx2keras) (4.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow->onnx2keras) (2.19.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow->onnx2keras) (0.1.2)\n","Building wheels for collected packages: onnx2keras\n","  Building wheel for onnx2keras (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for onnx2keras: filename=onnx2keras-0.0.24-py3-none-any.whl size=24576 sha256=123aa01baaf43718990efd46a0af5738e19c95499bcf8f3b57cda0d44aab26d2\n","  Stored in directory: /root/.cache/pip/wheels/3e/2c/e2/eb2ef49a50cab50b6d29557da4fefe10af3e9284412d7ef4f9\n","Successfully built onnx2keras\n","Installing collected packages: onnx2keras\n","Successfully installed onnx2keras-0.0.24\n"]}],"source":["!pip install onnx # to load the onnx model\n","!pip install onnxruntime # to load the onnx model\n","!pip install onnx2keras # to convert an onnx-model to keras-model."]},{"cell_type":"markdown","metadata":{"id":"iXduZqCmuEST"},"source":["## <font color='green'>1. PyTorch to ONNX</font>\n","\n","PyTorch provides us a very easy-to-use function to convert a PyTorch model to an ONNX format ending with an extension `.onnx`.\n","\n","Let's go ahead and see how we can do it."]},{"cell_type":"code","execution_count":2,"metadata":{"id":"EonGtDIEuESW","executionInfo":{"status":"ok","timestamp":1756301491131,"user_tz":-120,"elapsed":10899,"user":{"displayName":"Dirk Adler","userId":"10888330956412535296"}}},"outputs":[],"source":["# We will need to import the necessary libraries\n","import onnx\n","import onnxruntime\n","import torch\n","from torchvision import models\n","import numpy as np"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hkMEa2hGuESZ","executionInfo":{"status":"ok","timestamp":1756301494387,"user_tz":-120,"elapsed":568,"user":{"displayName":"Dirk Adler","userId":"10888330956412535296"}},"outputId":"43bd3d16-ba4a-4a2c-b8eb-28d991189b21"},"outputs":[{"output_type":"stream","name":"stdout","text":["The output from the PyTorch model:  tensor(-48.9275)\n"]}],"source":["# Pick a model from torchvision to port it to ONNX.\n","# We shall use the `resnet18()` to port it to ONNX.\n","resnet = models.resnet18()\n","\n","# Place the model in `evaluation-mode`\n","resnet.eval()\n","# Create a random input and get the output\n","ip = torch.randn(1,3, 224, 224)\n","with torch.no_grad():\n","    op = resnet(ip)\n","\n","# Lets take the output-summation to see if we get the same output inferring through ONNX too\n","print(\"The output from the PyTorch model: \",op.sum())\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QKmMZrjJuESc","executionInfo":{"status":"ok","timestamp":1756301503957,"user_tz":-120,"elapsed":642,"user":{"displayName":"Dirk Adler","userId":"10888330956412535296"}},"outputId":"a8bcb09f-6219-4e53-86db-7ce6e2c9a194"},"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-2942324263.py:2: DeprecationWarning: You are using the legacy TorchScript-based ONNX export. Starting in PyTorch 2.9, the new torch.export-based ONNX exporter will be the default. To switch now, set dynamo=True in torch.onnx.export. This new exporter supports features like exporting LLMs with DynamicCache. We encourage you to try it and share feedback to help improve the experience. Learn more about the new export logic: https://pytorch.org/docs/stable/onnx_dynamo.html. For exporting control flow: https://pytorch.org/tutorials/beginner/onnx/export_control_flow_model_to_onnx_tutorial.html.\n","  torch.onnx.export(resnet, ip, \"resnet.onnx\" )\n"]}],"source":["# We shall convert the Pytorch model to ONNX using the function below.\n","torch.onnx.export(resnet, ip, \"resnet.onnx\" )"]},{"cell_type":"code","source":["# Export the model to ONNX format\n","torch.onnx.export(\n","    resnet,                     # The model to be exported\n","    ip,                         # The sample input tensor\n","    \"model.onnx\",               # The output file name\n","    export_params=True,         # Store the trained parameter weights inside the model file\n","    opset_version=12,           # The ONNX version to export the model to\n","    do_constant_folding=True,   # Whether to execute constant folding for optimization\n","    input_names=['input'],      # The model's input names\n","    output_names=['output'],    # The model's output names\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"miTMc4qcxDWv","executionInfo":{"status":"ok","timestamp":1756302344006,"user_tz":-120,"elapsed":613,"user":{"displayName":"Dirk Adler","userId":"10888330956412535296"}},"outputId":"f9d979d7-a0ba-4e36-caa2-298fc0ef8c8e"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-668913669.py:2: DeprecationWarning: You are using the legacy TorchScript-based ONNX export. Starting in PyTorch 2.9, the new torch.export-based ONNX exporter will be the default. To switch now, set dynamo=True in torch.onnx.export. This new exporter supports features like exporting LLMs with DynamicCache. We encourage you to try it and share feedback to help improve the experience. Learn more about the new export logic: https://pytorch.org/docs/stable/onnx_dynamo.html. For exporting control flow: https://pytorch.org/tutorials/beginner/onnx/export_control_flow_model_to_onnx_tutorial.html.\n","  torch.onnx.export(\n"]}]},{"cell_type":"markdown","metadata":{"id":"nz_5-MTHuESe"},"source":["##  <font color='green'>2. Inferring in ONNX</font>"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"V-d3NIfUuESh","executionInfo":{"status":"ok","timestamp":1756301508383,"user_tz":-120,"elapsed":39,"user":{"displayName":"Dirk Adler","userId":"10888330956412535296"}}},"outputs":[],"source":["## We need to create a session for inference when running an onnx model.\n","session = onnxruntime.InferenceSession(\"resnet.onnx\")\n","\n","# We also need to get the input_name.\n","input_name = session.get_inputs()[0].name\n","output_name = session.get_outputs()[0].name\n","\n","## Run the session be specifying our input at the node `input_name` and specifying that\n","## we need to break the graph at the node `output_name`\n","result = session.run([output_name], {input_name: ip.numpy()})"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pvdyy78vuESk","executionInfo":{"status":"ok","timestamp":1756301512125,"user_tz":-120,"elapsed":28,"user":{"displayName":"Dirk Adler","userId":"10888330956412535296"}},"outputId":"7c5bffcf-369a-45b3-caa4-e512804e23af"},"outputs":[{"output_type":"stream","name":"stdout","text":["The output from the ONNX model:  -48.927475\n"]}],"source":["## The `result` will be a list since we passed the outputs in the form of a list.\n","print(\"The output from the ONNX model: \",result[0].sum())"]},{"cell_type":"markdown","metadata":{"id":"TDVMuTEGuESn"},"source":["## <font color='green'>3. Inferring in OpenCV</font>\n","\n"," Often, the production environment is constrained to only a few libraries. And we cannot afford to use the `Pytorch` library, since we need it to only infer on the input.\n","\n","Hence, we need a way to load this `PyTorch` model into existing libraries, and one such library is `OpenCV`.\n","\n","Although the latest version of `OpenCV` already has support to load models from `TensorFlow`,  `Caffe`, etc., we don't have an API for loading `PyTorch` models. And, guess what, ONNX comes to our rescue here.\n","\n","In the following cell, we shall see how we can load the converted PyTorch model in OpenCV.\n"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"8WPQ3gOwuESp","executionInfo":{"status":"ok","timestamp":1756301530603,"user_tz":-120,"elapsed":146,"user":{"displayName":"Dirk Adler","userId":"10888330956412535296"}}},"outputs":[],"source":["# import the opencv library\n","import cv2\n","\n","# use the `readNetFromONNX` API to load the saved-onnx-model.\n","lenet_onnx = cv2.dnn.readNetFromONNX(\"resnet.onnx\")"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fOuUcUPnuESr","executionInfo":{"status":"ok","timestamp":1756301540257,"user_tz":-120,"elapsed":227,"user":{"displayName":"Dirk Adler","userId":"10888330956412535296"}},"outputId":"5d1896c0-694c-4d3a-d1f1-232bec53f194"},"outputs":[{"output_type":"stream","name":"stdout","text":["The output from the ONNX model when loaded via OpenCV:  -48.92751\n"]}],"source":["# we shall set the input to the network\n","lenet_onnx.setInput(ip.numpy())\n","\n","# get the output of model by calling the `forward()` method.\n","onnx_op = lenet_onnx.forward()\n","\n","# let's verify the sum of this output with the previous results.\n","print(\"The output from the ONNX model when loaded via OpenCV: \", onnx_op.sum())"]},{"cell_type":"markdown","metadata":{"id":"E93b2GgZuESu"},"source":["## <font color='green'>4. ONNX to Keras and Inferring in Keras</font>\n","\n","Sometimes, the production environment requires us to have a Tensorflow-based environment.  \n","\n","In that case, too, we can use the module `onnx2keras` to convert from `ONNX` to `Keras` and then save this model to the Keras format `.h5`"]},{"cell_type":"code","source":["!pip install --upgrade onnx2keras"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j5JwvyNnvgsZ","executionInfo":{"status":"ok","timestamp":1756301768050,"user_tz":-120,"elapsed":5379,"user":{"displayName":"Dirk Adler","userId":"10888330956412535296"}},"outputId":"43f5714d-45fc-4b31-cb94-ffe1b09ddccd"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: onnx2keras in /usr/local/lib/python3.12/dist-packages (0.0.24)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (from onnx2keras) (2.19.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from onnx2keras) (2.0.2)\n","Requirement already satisfied: onnx in /usr/local/lib/python3.12/dist-packages (from onnx2keras) (1.19.0)\n","Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.12/dist-packages (from onnx->onnx2keras) (5.29.5)\n","Requirement already satisfied: typing_extensions>=4.7.1 in /usr/local/lib/python3.12/dist-packages (from onnx->onnx2keras) (4.14.1)\n","Requirement already satisfied: ml_dtypes in /usr/local/lib/python3.12/dist-packages (from onnx->onnx2keras) (0.5.3)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->onnx2keras) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->onnx2keras) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow->onnx2keras) (25.2.10)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow->onnx2keras) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow->onnx2keras) (0.2.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->onnx2keras) (18.1.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow->onnx2keras) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow->onnx2keras) (25.0)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->onnx2keras) (2.32.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow->onnx2keras) (75.2.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->onnx2keras) (1.17.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->onnx2keras) (3.1.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->onnx2keras) (1.17.3)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow->onnx2keras) (1.74.0)\n","Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->onnx2keras) (2.19.0)\n","Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->onnx2keras) (3.10.0)\n","Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow->onnx2keras) (3.14.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow->onnx2keras) (0.45.1)\n","Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow->onnx2keras) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow->onnx2keras) (0.1.0)\n","Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow->onnx2keras) (0.17.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow->onnx2keras) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow->onnx2keras) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow->onnx2keras) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow->onnx2keras) (2025.8.3)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow->onnx2keras) (3.8.2)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow->onnx2keras) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow->onnx2keras) (3.1.3)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow->onnx2keras) (3.0.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow->onnx2keras) (4.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow->onnx2keras) (2.19.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow->onnx2keras) (0.1.2)\n"]}]},{"cell_type":"code","execution_count":13,"metadata":{"id":"kuyZHJnquESv","executionInfo":{"status":"ok","timestamp":1756301768296,"user_tz":-120,"elapsed":6,"user":{"displayName":"Dirk Adler","userId":"10888330956412535296"}}},"outputs":[],"source":["# importing the onnx_to_keras function\n","from onnx2keras import onnx_to_keras"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"s68SZl1FuESx","executionInfo":{"status":"ok","timestamp":1756302366816,"user_tz":-120,"elapsed":48,"user":{"displayName":"Dirk Adler","userId":"10888330956412535296"}}},"outputs":[],"source":["# load the onnx-model converted from pytorch.\n","onnx_model = onnx.load(\"model.onnx\")"]},{"cell_type":"code","source":["k_model = onnx_to_keras(onnx_model, ['input'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":367},"id":"AcLmjSb4vsZS","executionInfo":{"status":"error","timestamp":1756302370479,"user_tz":-120,"elapsed":48,"user":{"displayName":"Dirk Adler","userId":"10888330956412535296"}},"outputId":"bdf65c77-efbe-40e4-a97b-9ad96dca5385"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/input_layer.py:27: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n","  warnings.warn(\n"]},{"output_type":"error","ename":"ValueError","evalue":"Argument `name` must be a string and cannot contain character `/`. Received: name=/conv1/Conv_output_0_pad (of type <class 'str'>)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3430692456.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mk_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monnx_to_keras\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monnx_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'input'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/onnx2keras/converter.py\u001b[0m in \u001b[0;36monnx_to_keras\u001b[0;34m(onnx_model, input_names, input_shapes, name_policy, verbose, change_ordering)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_image_data_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'channels_first'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         AVAILABLE_CONVERTERS[node_type](\n\u001b[0m\u001b[1;32m    176\u001b[0m             \u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mnode_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/onnx2keras/convolution_layers.py\u001b[0m in \u001b[0;36mconvert_conv\u001b[0;34m(node, params, layers, lambda_func, node_name, keras_name)\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Paddings exist, add ZeroPadding layer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mpadding_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_pad'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             padding_layer = keras.layers.ZeroPadding2D(\n\u001b[0m\u001b[1;32m     87\u001b[0m                 \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/zero_padding2d.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, padding, data_format, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstandardize_data_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/layers/layer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, activity_regularizer, trainable, dtype, autocast, name, **kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0mBackendLayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m         \u001b[0mOperation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivity_regularizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregularizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivity_regularizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0minput_dim_arg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"input_dim\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/ops/operation.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dtype, name)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauto_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"/\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m     22\u001b[0m                 \u001b[0;34m\"Argument `name` must be a string and \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0;34m\"cannot contain character `/`. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Argument `name` must be a string and cannot contain character `/`. Received: name=/conv1/Conv_output_0_pad (of type <class 'str'>)"]}]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":420},"id":"Q2vk0YP4uESx","executionInfo":{"status":"error","timestamp":1756301774556,"user_tz":-120,"elapsed":125,"user":{"displayName":"Dirk Adler","userId":"10888330956412535296"}},"outputId":"39e31eb7-f319-41c9-e858-24de19c8f236"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/input_layer.py:27: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n","  warnings.warn(\n"]},{"output_type":"error","ename":"ValueError","evalue":"Argument `name` must be a string and cannot contain character `/`. Received: name=/conv1/Conv_output_0_pad (of type <class 'str'>)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1521205038.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# makes the model portable to input shape (B, H, W, C).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mkeras_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monnx_to_keras\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monnx_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0monnx_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchange_ordering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# this `keras_model` is now the Resnet-graph built in Keras.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/onnx2keras/converter.py\u001b[0m in \u001b[0;36monnx_to_keras\u001b[0;34m(onnx_model, input_names, input_shapes, name_policy, verbose, change_ordering)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_image_data_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'channels_first'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         AVAILABLE_CONVERTERS[node_type](\n\u001b[0m\u001b[1;32m    176\u001b[0m             \u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mnode_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/onnx2keras/convolution_layers.py\u001b[0m in \u001b[0;36mconvert_conv\u001b[0;34m(node, params, layers, lambda_func, node_name, keras_name)\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Paddings exist, add ZeroPadding layer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mpadding_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_pad'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             padding_layer = keras.layers.ZeroPadding2D(\n\u001b[0m\u001b[1;32m     87\u001b[0m                 \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/zero_padding2d.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, padding, data_format, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstandardize_data_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/layers/layer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, activity_regularizer, trainable, dtype, autocast, name, **kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0mBackendLayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m         \u001b[0mOperation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivity_regularizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregularizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivity_regularizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0minput_dim_arg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"input_dim\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/ops/operation.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dtype, name)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauto_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"/\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m     22\u001b[0m                 \u001b[0;34m\"Argument `name` must be a string and \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0;34m\"cannot contain character `/`. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Argument `name` must be a string and cannot contain character `/`. Received: name=/conv1/Conv_output_0_pad (of type <class 'str'>)"]}],"source":["# we shall specify the required arguments to the function. The argument `change_ordering`\n","# makes the model portable to input shape (B, H, W, C).\n","\n","keras_model = onnx_to_keras(onnx_model=onnx_model, input_names=[input_name], change_ordering=True)\n","# this `keras_model` is now the Resnet-graph built in Keras."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mJb1EIWKuESz","outputId":"412a5cd9-e753-4324-f262-f115aac1f5a5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Output sum when converting from ONNX to Keras:  -3.2902946\n"]}],"source":["# We can now use this graph to verify if we get the same results.\n","\n","# We should use the `predict()` method to call the evaluation-mode.\n","# Also note that, the input is permuted from [B, C, H, W] to [B, H, W, C].\n","\n","keras_op = keras_model.predict(ip.permute(0, 2, 3, 1).numpy())\n","print(\"Output sum when converting from ONNX to Keras: \", keras_op.sum())"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}