{"cells":[{"cell_type":"markdown","metadata":{"id":"BF7h3C_Bt2QC"},"source":["# <font style=\"color:blue\">SSD using PyTorch Hub</font>\n","\n","In this notenook, we will inference the SSD model using PyTorch Hub.\n","\n","First, we will see what PyTorch Hub is. Then we will load the SSD model from [NVIDIA/DeepLearningExamples:torchhub](https://github.com/NVIDIA/DeepLearningExamples/tree/torchhub) GitHub repository using PyTorch Hub make inference on a few sample data."]},{"cell_type":"markdown","metadata":{"id":"H1h9Pq7-t2QE"},"source":["# <font style=\"color:blue\">1. Introduction to PyTorch Hub</font>\n","\n","- Pytorch Hub is an API that provides pre-trained models to facilitate research reproducibility.\n","\n","\n","- It has built-in support for [Colab](https://colab.research.google.com/) and [Paper with Code](https://paperswithcode.com/).\n","\n","\n","- It has a broad set model that includes classification, detection, segmentation, etc. Get list of available model [here](https://pytorch.org/hub/research-models/compact)\n","\n","---\n","\n","<img src='https://www.learnopencv.com/wp-content/uploads/2020/03/c3-w9-pytorch-hub.png'>\n","\n","---\n","\n","- It also supports publishing a pre-trained model to a Github repository. Get details [here](https://pytorch.org/docs/stable/hub.html).\n"]},{"cell_type":"markdown","metadata":{"id":"jzG2EeTgt2QF"},"source":["## <font style=\"color:green\">List Supported Model</font>\n","\n","PyTorch Hub APIs only work if repository has hubconf.py file, for example [hubconf.py](https://github.com/NVIDIA/DeepLearningExamples/blob/torchhub/hubconf.py) file in [NVIDIA/DeepLearningExamples:torchhub](https://github.com/NVIDIA/DeepLearningExamples/tree/torchhub)."]},{"cell_type":"code","execution_count":1,"metadata":{"id":"Ggyn2gmvt2QF","executionInfo":{"status":"ok","timestamp":1724311739662,"user_tz":-120,"elapsed":288,"user":{"displayName":"Dirk Adler","userId":"10888330956412535296"}}},"outputs":[],"source":["%matplotlib inline"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"HkqlrkBpt2QG","executionInfo":{"status":"ok","timestamp":1724311745903,"user_tz":-120,"elapsed":3668,"user":{"displayName":"Dirk Adler","userId":"10888330956412535296"}}},"outputs":[],"source":["from matplotlib import pyplot as plt\n","import matplotlib.patches as patches\n","import torch"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w3ZwoaA3t2QG","executionInfo":{"status":"ok","timestamp":1724311846879,"user_tz":-120,"elapsed":7700,"user":{"displayName":"Dirk Adler","userId":"10888330956412535296"}},"outputId":"7c167beb-fa94-444e-8d81-a17999f1105e"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/hub.py:293: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or list(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use list(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n","  warnings.warn(\n","Downloading: \"https://github.com/NVIDIA/DeepLearningExamples/zipball/torchhub\" to /root/.cache/torch/hub/torchhub.zip\n","/root/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub/PyTorch/Classification/ConvNets/image_classification/models/common.py:13: UserWarning: pytorch_quantization module not found, quantization will not be available\n","  warnings.warn(\n","/root/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub/PyTorch/Classification/ConvNets/image_classification/models/efficientnet.py:17: UserWarning: pytorch_quantization module not found, quantization will not be available\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["['nvidia_convnets_processing_utils',\n"," 'nvidia_efficientnet',\n"," 'nvidia_efficientnet_b0',\n"," 'nvidia_efficientnet_b4',\n"," 'nvidia_efficientnet_widese_b0',\n"," 'nvidia_efficientnet_widese_b4',\n"," 'nvidia_fastpitch',\n"," 'nvidia_gpunet',\n"," 'nvidia_hifigan',\n"," 'nvidia_resneXt',\n"," 'nvidia_resnet50',\n"," 'nvidia_resnext101_32x4d',\n"," 'nvidia_se_resnext101_32x4d',\n"," 'nvidia_ssd',\n"," 'nvidia_ssd_processing_utils',\n"," 'nvidia_tacotron2',\n"," 'nvidia_textprocessing_utils',\n"," 'nvidia_tft',\n"," 'nvidia_tft_data_utils',\n"," 'nvidia_tts_utils',\n"," 'nvidia_waveglow']"]},"metadata":{},"execution_count":3}],"source":["torch.hub.list(github='NVIDIA/DeepLearningExamples:torchhub', force_reload=False)"]},{"cell_type":"markdown","metadata":{"id":"8nmFV8A8t2QG"},"source":["## <font style=\"color:green\">Get Model Description</font>"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":71},"id":"2827xBSzt2QH","executionInfo":{"status":"ok","timestamp":1724311854297,"user_tz":-120,"elapsed":318,"user":{"displayName":"Dirk Adler","userId":"10888330956412535296"}},"outputId":"1b485620-2053-4ea2-e4fb-ba34e5d72f12"},"outputs":[{"output_type":"stream","name":"stderr","text":["Using cache found in /root/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub\n"]},{"output_type":"execute_result","data":{"text/plain":["\"Constructs an SSD300 model.\\n    For detailed information on model input and output, training recipies, inference and performance\\n    visit: github.com/NVIDIA/DeepLearningExamples and/or ngc.nvidia.com\\n    Args:\\n        pretrained (bool, True): If True, returns a model pretrained on COCO dataset.\\n        model_math (str, 'fp32'): returns a model in given precision ('fp32' or 'fp16')\\n    \""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":4}],"source":["torch.hub.help(github='NVIDIA/DeepLearningExamples:torchhub',\n","               model='nvidia_ssd',\n","               force_reload=False)"]},{"cell_type":"markdown","metadata":{"id":"wkiyImW7t2QH"},"source":["# <font style=\"color:blue\">2. SSD model Inference using PyTorch Hub</font>\n","\n","- We are already familiar with SSD (Single Shot MultiBox Detector). You can find the paper [here](https://arxiv.org/pdf/1512.02325.pdf).\n","\n","---\n","\n","<img src=https://www.learnopencv.com/wp-content/uploads/2020/03/c3-w9-ssd.png width=1000>\n","\n","<center>Image credits: Liu et al</center>\n","\n","---\n","\n","\n","- We will use the pre-trained SSD model by Nvidia. You can find other different models from Nvidia [here](https://github.com/NVIDIA/DeepLearningExamples/tree/torchhub/PyTorch).\n","\n","\n","- SSD implementation of Nvidia is a variant of [the original paper](https://arxiv.org/pdf/1512.02325.pdf).\n","\n","\n","## <font style=\"color:green\">Model Description</font>\n","\n","This SSD300 model is based on the\n","[SSD: Single Shot MultiBox Detector](https://arxiv.org/abs/1512.02325) paper, which\n","describes SSD as \"a method for detecting objects in images using a single deep neural network\".\n","The input size is fixed to `300x300`.\n","\n","The main difference between this model and the one described in the paper is in the backbone.\n","Specifically, the VGG model is obsolete and is replaced by the ResNet-50 model.\n","\n","From the\n","[Speed/accuracy trade-offs for modern convolutional object detectors](https://arxiv.org/abs/1611.10012)\n","paper, the following enhancements were made to the backbone:\n","*   The `conv5_x`, `avgpool`, `fc` and softmax layers were removed from the original classification model.\n","*   All strides in `conv4_x` are set to `1x1`.\n","\n","The backbone is followed by 5 additional convolutional layers.\n","In addition to the convolutional layers, we attached 6 detection heads:\n","*   The first detection head is attached to the last `conv4_x` layer.\n","*   The other five detection heads are attached to the corresponding `5` additional layers.\n","\n","Detector heads are similar to the ones referenced in the paper, however,\n","they are enhanced by additional BatchNorm layers after each convolution.\n","\n","**If you are interested in original SSD paper implementation, you can find [here](https://github.com/amdegroot/ssd.pytorch/blob/master/ssd.py).**"]},{"cell_type":"markdown","metadata":{"id":"f0lO5_C9t2QH"},"source":["## <font style=\"color:green\">Load the Model using PyTorch Hub</font>\n","\n","- The model has been trained on two precession- `float16` (`fp16`) and `float32` (`fp32`).\n","\n","\n","- The benefit of `fp16` is heigh inference speed compare to `fp32` at the cost of accuracy/precision.\n","\n","\n","- Setting precision=`fp16` will load a checkpoint trained with [mixed precision](https://arxiv.org/abs/1710.03740) into architecture enabling execution on [Tensor Cores](https://developer.nvidia.com/tensor-cores).\n","Handling mixed precision data requires [Apex](https://github.com/NVIDIA/apex) library.\n","\n","\n","\n","Let's load the SSD (by Nvidia) model using PyTorch Hub.\n"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1uWYl6vot2QH","executionInfo":{"status":"ok","timestamp":1724311866826,"user_tz":-120,"elapsed":4747,"user":{"displayName":"Dirk Adler","userId":"10888330956412535296"}},"outputId":"afcb1897-fea6-41cd-bc3e-7ec53eda408c"},"outputs":[{"output_type":"stream","name":"stderr","text":["Using cache found in /root/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub\n","Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n","100%|██████████| 97.8M/97.8M [00:00<00:00, 182MB/s]\n","Downloading checkpoint from https://api.ngc.nvidia.com/v2/models/nvidia/ssd_pyt_ckpt_amp/versions/20.06.0/files/nvidia_ssdpyt_amp_200703.pt\n"]}],"source":["precision = 'fp32'\n","ssd = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_ssd', model_math=precision)"]},{"cell_type":"markdown","metadata":{"id":"5ZHIvIMpt2QH"},"source":["## <font style=\"color:green\">Load the Utils Function</font>"]},{"cell_type":"code","execution_count":6,"metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"ciuTNAMgt2QH","executionInfo":{"status":"ok","timestamp":1724311869693,"user_tz":-120,"elapsed":285,"user":{"displayName":"Dirk Adler","userId":"10888330956412535296"}},"outputId":"0d126546-87ed-4a8b-bd29-909a53f21e47"},"outputs":[{"output_type":"stream","name":"stderr","text":["Using cache found in /root/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub\n"]}],"source":["utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_ssd_processing_utils')"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0ayme3WVt2QI","executionInfo":{"status":"ok","timestamp":1724311873139,"user_tz":-120,"elapsed":458,"user":{"displayName":"Dirk Adler","userId":"10888330956412535296"}},"outputId":"734af4c6-8b2f-41ce-8964-d70d8d4f21a8"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["SSD300(\n","  (feature_extractor): ResNet(\n","    (feature_extractor): Sequential(\n","      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU(inplace=True)\n","      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","      (4): Sequential(\n","        (0): Bottleneck(\n","          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (2): Bottleneck(\n","          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","      )\n","      (5): Sequential(\n","        (0): Bottleneck(\n","          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (2): Bottleneck(\n","          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (3): Bottleneck(\n","          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","      )\n","      (6): Sequential(\n","        (0): Bottleneck(\n","          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","          (downsample): Sequential(\n","            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          )\n","        )\n","        (1): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (2): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (3): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (4): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","        (5): Bottleneck(\n","          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (relu): ReLU(inplace=True)\n","        )\n","      )\n","    )\n","  )\n","  (additional_blocks): ModuleList(\n","    (0): Sequential(\n","      (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU(inplace=True)\n","      (3): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (5): ReLU(inplace=True)\n","    )\n","    (1): Sequential(\n","      (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU(inplace=True)\n","      (3): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (5): ReLU(inplace=True)\n","    )\n","    (2): Sequential(\n","      (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU(inplace=True)\n","      (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (5): ReLU(inplace=True)\n","    )\n","    (3-4): 2 x Sequential(\n","      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU(inplace=True)\n","      (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (5): ReLU(inplace=True)\n","    )\n","  )\n","  (loc): ModuleList(\n","    (0): Conv2d(1024, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1-2): 2 x Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (4-5): 2 x Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  )\n","  (conf): ModuleList(\n","    (0): Conv2d(1024, 324, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1-2): 2 x Conv2d(512, 486, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): Conv2d(256, 486, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (4-5): 2 x Conv2d(256, 324, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  )\n",")"]},"metadata":{},"execution_count":7}],"source":["ssd.to('cuda')\n","ssd.eval()"]},{"cell_type":"markdown","metadata":{"id":"QEl3rhAlt2QI"},"source":["## <font style=\"color:green\">Input Images</font>\n","\n","- Pre-process inputs images for SSD object detection.\n","\n","\n","- Here, Image URLs have been used. You can use your images.\n"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"U_Xp56sFt2QI","executionInfo":{"status":"ok","timestamp":1724311877484,"user_tz":-120,"elapsed":276,"user":{"displayName":"Dirk Adler","userId":"10888330956412535296"}}},"outputs":[],"source":["urls = [\n","    'http://images.cocodataset.org/test2017/000000550803.jpg',\n","    'http://images.cocodataset.org/test2017/000000004053.jpg',\n","    'http://images.cocodataset.org/test2017/000000426603.jpg',\n","    'http://images.cocodataset.org/test2017/000000491276.jpg'\n","]"]},{"cell_type":"markdown","metadata":{"id":"9D21A8Ywt2QI"},"source":["### <font style=\"color:green\">Image Pre-process</font>"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"buKHm75Qt2QI","executionInfo":{"status":"ok","timestamp":1724311882600,"user_tz":-120,"elapsed":2565,"user":{"displayName":"Dirk Adler","userId":"10888330956412535296"}}},"outputs":[],"source":["inputs = [utils.prepare_input(url) for url in urls]\n","tensor = utils.prepare_tensor(inputs, precision == 'fp16')"]},{"cell_type":"markdown","metadata":{"id":"ifaZua64t2QI"},"source":["## <font style=\"color:green\">Inference</font>"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"U2OucBbmt2QI","executionInfo":{"status":"ok","timestamp":1724311885948,"user_tz":-120,"elapsed":1304,"user":{"displayName":"Dirk Adler","userId":"10888330956412535296"}}},"outputs":[],"source":["with torch.no_grad():\n","    detections = ssd(tensor)"]},{"cell_type":"markdown","metadata":{"id":"nT18vnIqt2QI"},"source":["### <font style=\"color:green\">Image Post-process</font>"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"cToB0CnEt2QI","executionInfo":{"status":"ok","timestamp":1724311889302,"user_tz":-120,"elapsed":1540,"user":{"displayName":"Dirk Adler","userId":"10888330956412535296"}}},"outputs":[],"source":["results = utils.decode_results(detections)\n","best_results = [utils.pick_best(results, 0.40) for results in results]"]},{"cell_type":"markdown","metadata":{"id":"uFM7pd2ut2QI"},"source":["## <font style=\"color:green\">Get Class to Label Map</font>"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Or-UQWhrt2QI","executionInfo":{"status":"ok","timestamp":1724311916129,"user_tz":-120,"elapsed":25674,"user":{"displayName":"Dirk Adler","userId":"10888330956412535296"}},"outputId":"3041a3b6-ef92-4843-b272-06f8a611c575"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading COCO annotations.\n","Downloading finished.\n"]}],"source":["classes_to_labels = utils.get_coco_object_dictionary()"]},{"cell_type":"markdown","metadata":{"id":"uebsC4P6t2QI"},"source":["## <font style=\"color:green\">Plot Detections</font>"]},{"cell_type":"code","execution_count":13,"metadata":{"scrolled":false,"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1Wsh06bVPbFvKawQLCO64XhDkNcdDB4DA"},"id":"cVoeKnGCt2QJ","executionInfo":{"status":"ok","timestamp":1724311948809,"user_tz":-120,"elapsed":3503,"user":{"displayName":"Dirk Adler","userId":"10888330956412535296"}},"outputId":"c4b947cb-5190-40eb-8cdc-ea26923b1bd2"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["for image_idx in range(len(best_results)):\n","    fig, ax = plt.subplots(1, figsize=(7,7))\n","    # Show original, denormalized image...\n","    image = inputs[image_idx] / 2 + 0.5\n","    ax.imshow(image)\n","    # ...with detections\n","    bboxes, classes, confidences = best_results[image_idx]\n","    for idx in range(len(bboxes)):\n","        left, bot, right, top = bboxes[idx]\n","        x, y, w, h = [val * 300 for val in [left, bot, right - left, top - bot]]\n","        rect = patches.Rectangle((x, y), w, h, linewidth=1, edgecolor='r', facecolor='none')\n","        ax.add_patch(rect)\n","        ax.text(x, y, \"{} {:.0f}%\".format(classes_to_labels[classes[idx] - 1], confidences[idx]*100), bbox=dict(facecolor='white', alpha=0.5))\n","\n","    plt.show()"]},{"cell_type":"markdown","metadata":{"id":"RUgUUciDt2QJ"},"source":["# <font style=\"color:blue\">References</font>\n","\n","- [SSD: Single Shot MultiBox Detector](https://arxiv.org/pdf/1512.02325.pdf)\n","\n","\n","- [PyTorch Hub](https://pytorch.org/docs/stable/hub.html)\n","\n","\n","- [NVIDIA DeepLearningExamples:PyTorch SSD](https://github.com/NVIDIA/DeepLearningExamples/tree/torchhub/PyTorch/Detection/SSD)\n","\n","\n","- [PyTorch Hub: Docs](https://pytorch.org/hub/nvidia_deeplearningexamples_ssd/)\n","\n","\n","- [PyTorch Blog: Towards reproducible research with pytorch hub](https://pytorch.org/blog/towards-reproducible-research-with-pytorch-hub/)\n","\n","\n","- [SSD PyTorch Github](https://github.com/amdegroot/ssd.pytorch/blob/master/ssd.py)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZR-KGRg8t2QJ"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}