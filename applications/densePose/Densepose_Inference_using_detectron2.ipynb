{"cells":[{"cell_type":"markdown","metadata":{"id":"suDdF3twpOq9"},"source":["# <font style=\"color:blue\">Densepose Inference using detectron2</font>\n","Detectron2 provides 2 tools to visualize dataset and run inference on test images.\n","- **Apply Net**\n","    - A tool to print or visualize DensePose results on a set of images. It has two modes: dump to save DensePose model results to a pickle file and show to visualize them on images\n","\n","- **Query Db**\n","    -  A tool to print or visualize DensePose data from a dataset. It has two modes: print and show to output dataset entries to standard output or to visualize them on images.\n","\n","We will use apply net in this notebook. Query db is to visualize any dataset which will be of use while training in the next notebook."]},{"cell_type":"markdown","metadata":{"id":"GqqgrlSnpOrC"},"source":["## <font style=\"color:green\">1. Setup Code</font>\n","\n","To use the above tools, we have to download the densepose project from detectron2."]},{"cell_type":"code","source":["# install dependencies\n","!pip install -U torch torchvision cython\n","!pip install -U 'git+https://github.com/facebookresearch/fvcore.git' 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n","import torch, torchvision\n","torch.__version__"],"metadata":{"id":"BxnhzVdX0uoM"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cNfQEMpcpOrE"},"outputs":[],"source":["!#git clone https://github.com/facebookresearch/detectron2.git"]},{"cell_type":"code","source":["!git clone https://github.com/facebookresearch/detectron2 detectron2\n","!pip install -e detectron2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UymPwuqM0zvf","executionInfo":{"status":"ok","timestamp":1742832618897,"user_tz":-60,"elapsed":16791,"user":{"displayName":"Dirk Adler","userId":"10888330956412535296"}},"outputId":"0bc771e4-1959-45f6-c52c-dc42d60949e0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'detectron2' already exists and is not an empty directory.\n","Obtaining file:///content/detectron2\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (11.1.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (3.10.0)\n","Collecting pycocotools>=2.0.2 (from detectron2==0.6)\n","  Using cached pycocotools-2.0.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n","Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (2.5.0)\n","Requirement already satisfied: yacs>=0.1.8 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (0.1.8)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (0.9.0)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (3.1.1)\n","Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (4.67.1)\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (2.18.0)\n","Collecting fvcore<0.1.6,>=0.1.5 (from detectron2==0.6)\n","  Using cached fvcore-0.1.5.post20221221-py3-none-any.whl\n","Requirement already satisfied: iopath<0.1.10,>=0.1.7 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (0.1.9)\n","Requirement already satisfied: omegaconf<2.4,>=2.1 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (2.3.0)\n","Requirement already satisfied: hydra-core>=1.1 in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (1.3.2)\n","Requirement already satisfied: black in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (25.1.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from detectron2==0.6) (24.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (2.0.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (6.0.2)\n","Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from hydra-core>=1.1->detectron2==0.6) (4.9.3)\n","Requirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (from iopath<0.1.10,>=0.1.7->detectron2==0.6) (3.1.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->detectron2==0.6) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->detectron2==0.6) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->detectron2==0.6) (4.56.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->detectron2==0.6) (1.4.8)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->detectron2==0.6) (3.2.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->detectron2==0.6) (2.8.2)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from black->detectron2==0.6) (8.1.8)\n","Requirement already satisfied: mypy-extensions>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from black->detectron2==0.6) (1.0.0)\n","Requirement already satisfied: pathspec>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from black->detectron2==0.6) (0.12.1)\n","Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.11/dist-packages (from black->detectron2==0.6) (4.3.6)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (1.71.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (3.7)\n","Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (5.29.3)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (75.1.0)\n","Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (1.17.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard->detectron2==0.6) (3.1.3)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard->detectron2==0.6) (3.0.2)\n","Using cached pycocotools-2.0.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (458 kB)\n","Installing collected packages: fvcore, pycocotools, detectron2\n","  Attempting uninstall: fvcore\n","    Found existing installation: fvcore 0.1.6\n","    Uninstalling fvcore-0.1.6:\n","      Successfully uninstalled fvcore-0.1.6\n","  Attempting uninstall: pycocotools\n","    Found existing installation: pycocotools 2.0\n","    Uninstalling pycocotools-2.0:\n","      Successfully uninstalled pycocotools-2.0\n","  Attempting uninstall: detectron2\n","    Found existing installation: detectron2 0.6\n","    Uninstalling detectron2-0.6:\n","      Successfully uninstalled detectron2-0.6\n","  Running setup.py develop for detectron2\n","Successfully installed detectron2-0.6 fvcore-0.1.5.post20221221 pycocotools-2.0.8\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DCESQxGbpOrH","executionInfo":{"status":"ok","timestamp":1742832628128,"user_tz":-60,"elapsed":4,"user":{"displayName":"Dirk Adler","userId":"10888330956412535296"}},"outputId":"f8ed86b4-a144-488a-db26-e22b7fc0f7b4"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/detectron2/projects/DensePose\n"]}],"source":["%cd detectron2/projects/DensePose"]},{"cell_type":"markdown","metadata":{"id":"nSSwWmPjpOrI"},"source":["## <font style=\"color:green\">2. Import Config and Model files</font>\n","\n","Densepose config file can be found at `detectron2/projects/DensePose/configs/densepose_rcnn_R_50_FPN_s1x.yaml`\n","\n","Model weights files can be found <a href=\"https://github.com/facebookresearch/detectron2/blob/master/projects/DensePose/doc/MODEL_ZOO.md\" target=\"_blank\">here</a>. From the link, we have used improved baselines with original fully convolutional head."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9drUdWb7pOrJ"},"outputs":[],"source":["import urllib\n","\n","def download(url, filepath):\n","    response = urllib.request.urlretrieve(url, filepath)\n","    return response"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FiMYiG3xpOrK","executionInfo":{"status":"ok","timestamp":1742832633210,"user_tz":-60,"elapsed":1981,"user":{"displayName":"Dirk Adler","userId":"10888330956412535296"}},"outputId":"92204225-d287-4d52-c7af-9f25f33c3c0a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["('model_final_162be9.pkl', <http.client.HTTPMessage at 0x7f18533dc790>)"]},"metadata":{},"execution_count":5}],"source":["download(\"https://dl.fbaipublicfiles.com/densepose/densepose_rcnn_R_50_FPN_s1x/165712039/model_final_162be9.pkl\",\n","         \"model_final_162be9.pkl\")"]},{"cell_type":"markdown","metadata":{"id":"kS_BEulXpOrN"},"source":["Based on the major functions of apply net, now lets see how we can run inference on Video using detectron2's densepose."]},{"cell_type":"markdown","metadata":{"id":"lD0Lzui-pOrP"},"source":["## <font style=\"color:green\">3. Inference on Video</font>\n","\n","### 3.1. Import Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aOmgQQXtpOrT","executionInfo":{"status":"ok","timestamp":1742832651454,"user_tz":-60,"elapsed":6,"user":{"displayName":"Dirk Adler","userId":"10888330956412535296"}},"outputId":"6c169bcc-00ff-4119-c069-9df6e344818e"},"outputs":[{"output_type":"stream","name":"stdout","text":["File location using os.getcwd(): /content/detectron2/projects/DensePose\n"]}],"source":["import os\n","import sys\n","\n","print(\"File location using os.getcwd():\", os.getcwd())\n"]},{"cell_type":"code","source":["sys.path.insert(0,'/content/detectron2')"],"metadata":{"id":"xdrwpKfFr035"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OT2uKBz6pOrW"},"outputs":[],"source":["import cv2\n","import numpy as np\n","\n","from typing import ClassVar, Dict\n","\n","from detectron2.config import get_cfg\n","from detectron2.structures.instances import Instances\n","from detectron2.engine.defaults import DefaultPredictor\n","\n","from densepose import add_densepose_config\n","from densepose.vis.base import CompoundVisualizer\n","from densepose.vis.bounding_box import ScoredBoundingBoxVisualizer\n","from densepose.vis.extractor import CompoundExtractor, create_extractor\n","\n","from densepose.vis.densepose_results import (\n","    DensePoseResultsContourVisualizer,\n","    DensePoseResultsFineSegmentationVisualizer,\n","    DensePoseResultsUVisualizer,\n","    DensePoseResultsVVisualizer,\n",")"]},{"cell_type":"markdown","metadata":{"id":"Ed-xkdyIpOrZ"},"source":["### Import Visualizers\n","- Below mentioned object contains the different visualization methods like contour, segmentation, U coordinates, V coordinates and bounding box.\n","\n","**Sample visualizer method**:\n","\n","```\n","class DensePoseResultsFineSegmentationVisualizer(DensePoseMaskedColormapResultsVisualizer):\n","    def __init__(self, inplace=True, cmap=cv2.COLORMAP_PARULA, alpha=0.7):\n","        super(DensePoseResultsFineSegmentationVisualizer, self).__init__(\n","            _extract_i_from_iuvarr,\n","            _extract_i_from_iuvarr,\n","            inplace,\n","            cmap,\n","            alpha,\n","            val_scale=255.0 / DensePoseDataRelative.N_PART_LABELS,\n","        )\n","```\n","\n","From above we can see how the segmentation visualizer **`DensePoseResultsFineSegmentationVisualizer`** works by calling other classes like **`DensePoseMaskedColormapResultsVisualizer`** which again calls **`DensePoseResultsVisualizer`** and few other functions like **`_extract_i_from_iuvarr`**.\n","\n","```\n","class DensePoseMaskedColormapResultsVisualizer(DensePoseResultsVisualizer):\n","    def __init__(\n","        self,\n","        data_extractor,\n","        segm_extractor,\n","        inplace=True,\n","        cmap=cv2.COLORMAP_PARULA,\n","        alpha=0.7,\n","        val_scale=1.0,\n","    ):\n","        self.mask_visualizer = MatrixVisualizer(\n","            inplace=inplace, cmap=cmap, val_scale=val_scale, alpha=alpha\n","        )\n","        self.data_extractor = data_extractor\n","        self.segm_extractor = segm_extractor\n","\n","    def create_visualization_context(self, image_bgr: Image):\n","        return image_bgr\n","\n","    def context_to_image_bgr(self, context):\n","        return context\n","\n","    def get_image_bgr_from_context(self, context):\n","        return context\n","\n","    def visualize_iuv_arr(self, context, iuv_arr, bbox_xywh):\n","        image_bgr = self.get_image_bgr_from_context(context)\n","        matrix = self.data_extractor(iuv_arr)\n","        segm = self.segm_extractor(iuv_arr)\n","        mask = np.zeros(matrix.shape, dtype=np.uint8)\n","        mask[segm > 0] = 1\n","        image_bgr = self.mask_visualizer.visualize(image_bgr, mask, matrix, bbox_xywh)\n","        return image_bgr\n","\n","\n","def _extract_i_from_iuvarr(iuv_arr):\n","    return iuv_arr[0, :, :]\n","\n","\n","def _extract_u_from_iuvarr(iuv_arr):\n","    return iuv_arr[1, :, :]\n","\n","\n","def _extract_v_from_iuvarr(iuv_arr):\n","    return iuv_arr[2, :, :]\n","```\n","\n","\n","```\n","class DensePoseResultsVisualizer(object):\n","    def visualize(self, image_bgr: Image, densepose_result: Optional[DensePoseResult]) -> Image:\n","        if densepose_result is None:\n","            return image_bgr\n","        context = self.create_visualization_context(image_bgr)\n","        for i, result_encoded_w_shape in enumerate(densepose_result.results):\n","            iuv_arr = DensePoseResult.decode_png_data(*result_encoded_w_shape)\n","            bbox_xywh = densepose_result.boxes_xywh[i]\n","            self.visualize_iuv_arr(context, iuv_arr, bbox_xywh)\n","        image_bgr = self.context_to_image_bgr(context)\n","        return image_bgr\n","```\n","\n","- Visualize function of `DensePoseResultsVisualizer` decoded densepose result data to get iuv_arr and corresponding bounding boxes.\n","- `visualize_iuv_arr` extracts matrix and segm from iuv_arr, since the selected visulization format is segm and I is also partwise segmentation, both the matrix and segm are same. In case of other visualizations, we may use `_extract_u_from_iuvarr` or `_extract_v_from_iuvarr`\n","- Mask of segmentation is generated.\n","- mask_visualizer uses `MatrixVisualizer` defined in `densepose/vis/base.py`\n","    - resizes the matrix, mask according to the bbox width, height.\n","    - multiples the matrix with val_scale, clips the matrix values to (0,255) and converts to the image format.\n","    - Then it applies color coding to the matrix image and the original image is colored accordingly."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cR_eIvsTpOra"},"outputs":[],"source":["## Visualizer methods\n","VISUALIZERS: ClassVar[Dict[str, object]] = {\n","    \"dp_contour\": DensePoseResultsContourVisualizer,\n","    \"dp_segm\": DensePoseResultsFineSegmentationVisualizer,\n","    \"dp_u\": DensePoseResultsUVisualizer,\n","    \"dp_v\": DensePoseResultsVVisualizer,\n","    \"bbox\": ScoredBoundingBoxVisualizer,\n","}"]},{"cell_type":"markdown","metadata":{"id":"ASANNiJupOra"},"source":["### 3.2. Setup Config\n","- It imports the default config and gets the densepose specific config `add_densepose_config` which can be viewed at `detectron2/projects/DensePose/densepose/config.py`.\n","- It also imports the config file and model weights file."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oltilf-NpOrb"},"outputs":[],"source":["def setConfig():\n","    cfg = get_cfg()\n","    add_densepose_config(cfg)\n","\n","    cfg.merge_from_file(\"configs/densepose_rcnn_R_50_FPN_s1x.yaml\")\n","    cfg.MODEL.DEVICE = \"cuda\"\n","    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n","\n","    cfg.MODEL.WEIGHTS = \"model_final_162be9.pkl\"\n","\n","    return cfg"]},{"cell_type":"markdown","metadata":{"id":"NMJJnRrRpOrc"},"source":["### 3.3. Visualizer and Extractor\n","- Initializes the visualizer and extractor method for the different types of visualizations given in the arguments.\n","- Simlutaneously multiple visulization formats can be selected which are handled by CompoundVisualizer and CompoundExtractor.\n","- These methods extract contour, segmentation or points information from IUV mapping output given by the densepose."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TUw4ZjVWpOrd"},"outputs":[],"source":["def getVisAndExtract(vis_specs):\n","    visualizers = []\n","    extractors = []\n","    for vis_spec in vis_specs:\n","        vis = VISUALIZERS[vis_spec]()\n","        visualizers.append(vis)\n","        extractor = create_extractor(vis)\n","        extractors.append(extractor)\n","    visualizer = CompoundVisualizer(visualizers)\n","    extractor = CompoundExtractor(extractors)\n","\n","    return extractor, visualizer"]},{"cell_type":"markdown","metadata":{"id":"W9o3G74rpOrf"},"source":["### 3.4. Create context\n","```\n","context = {\n","            \"extractor\": extractor,\n","            \"visualizer\": visualizer,\n","            \"out_fname\": args.output,\n","            \"entry_idx\": 0,\n","        }\n","```\n","- Creates context object with visualizer, extractor, output filename and entry idx. Here, we use only visualizer and extractor keys for our purpose."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HRDHB6d8pOrf"},"outputs":[],"source":["def createContext(extractor, visualizer):\n","    context = {\n","        \"extractor\": extractor,\n","        \"visualizer\": visualizer\n","    }\n","\n","    return context"]},{"cell_type":"markdown","metadata":{"id":"rpw0X1HppOrg"},"source":["### 3.5. Predict Image\n","- Extractor finds the IUV mapping of the detected humans in the image in the DensePoseOutput format.\n","- This output is processed in the visualizer to the viewable format like contours, points or segmentation."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2liVbfBVpOrh"},"outputs":[],"source":["def predict(img, predictor, context):\n","    outputs = predictor(img)['instances']\n","    image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","    image = np.tile(image[:, :, np.newaxis], [1, 1, 3])\n","    data = context[\"extractor\"](outputs)\n","    image_vis = context[\"visualizer\"].visualize(image, data)\n","    return image_vis"]},{"cell_type":"markdown","metadata":{"id":"D1W0sfnypOrj"},"source":["In the inference video function, we are performing detection for every 10th frame, which can be changed accordingly."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DrPZ8r8PpOrk"},"outputs":[],"source":["def inferenceOnVideo(videoPath, predictor, context):\n","    cap = cv2.VideoCapture(videoPath)\n","    cnt = 0\n","    n_frame = 10\n","\n","    output_frames = []\n","\n","    import time\n","\n","    while True:\n","        ret, im = cap.read()\n","\n","        if not ret:\n","            break\n","\n","        if cnt%n_frame == 0:\n","            output = predict(im, predictor, context)\n","            time.sleep(1)\n","            output_frames.append(output)\n","\n","        cnt = cnt + 1\n","\n","\n","    height, width, _ = output_frames[0].shape\n","    size = (width,height)\n","    out = cv2.VideoWriter(\"out.mp4\",cv2.VideoWriter_fourcc(*'mp4v'), 10, size)\n","\n","    for i in range(len(output_frames)):\n","        out.write(output_frames[i])\n","\n","    out.release()"]},{"cell_type":"markdown","metadata":{"id":"viTJi4XrpOrk"},"source":["### 3.6. Main Execution\n","- Define visulization formats to be used in vis_specs. {'bbox', 'dp_segm', 'dp_contour', 'dp_u', 'dp_v'}\n","- Initialize config\n","- Initialize detectron2's default predictor method.\n","- Define visualizer and extractor methods based on vis_specs\n","- Context created with required functions to use in the prediction\n","- All frames predicted by densepose are compiled to output video out.mp4\n"]},{"cell_type":"markdown","metadata":{"id":"LEVvgSgjpOrl"},"source":["**Download <a href=\"https://www.dropbox.com/s/kk4zjqcfm5yf1cp/test_cut.mp4?dl=1\" target=\"_blank\">test_cut.mp4</a>**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DHZdODHQpOrn","executionInfo":{"status":"ok","timestamp":1742832708861,"user_tz":-60,"elapsed":2461,"user":{"displayName":"Dirk Adler","userId":"10888330956412535296"}},"outputId":"1e6ad2e6-bde7-475a-80a7-19d9a189c3dc"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["('test_cut.mp4', <http.client.HTTPMessage at 0x7f1744db8e90>)"]},"metadata":{},"execution_count":16}],"source":["download('https://www.dropbox.com/s/kk4zjqcfm5yf1cp/test_cut.mp4?dl=1', 'test_cut.mp4')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8OxXXcr7pOrp","executionInfo":{"status":"ok","timestamp":1742832762884,"user_tz":-60,"elapsed":39847,"user":{"displayName":"Dirk Adler","userId":"10888330956412535296"}},"outputId":"274c29b0-1efd-4714-8046-5fb35ded49f1"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch/functional.py:539: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:3637.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"]}],"source":["vis_specs = ['dp_segm', 'bbox']\n","\n","cfg = setConfig()\n","\n","##Initialize predictor\n","predictor = DefaultPredictor(cfg)\n","\n","extractor, visualizer = getVisAndExtract(vis_specs)\n","\n","context = createContext(extractor, visualizer)\n","\n","inferenceOnVideo(\"test_cut.mp4\", predictor, context)"]},{"cell_type":"markdown","metadata":{"id":"UHb72rPupOrp"},"source":["## <font style=\"color:green\">References</font>\n","\n","- <a href=\"https://github.com/facebookresearch/detectron2\" target=\"_blank\">https://github.com/facebookresearch/detectron2</a>\n","- <a href=\"http://densepose.org/\" target=\"_blank\">http://densepose.org/</a>\n","- <a href=\"https://research.fb.com/downloads/densepose/\" target=\"_blank\">https://research.fb.com/downloads/densepose/</a>\n","- <a href=\"https://arxiv.org/pdf/1802.00434.pdf\" target=\"_blank\">https://arxiv.org/pdf/1802.00434.pdf</a>"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.3"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}