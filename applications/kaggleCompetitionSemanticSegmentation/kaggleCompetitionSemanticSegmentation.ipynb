{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5"},"source":["# <font style=\"color:blue\">Project 4: Kaggle Competition - Semantic Segmentation</font>\n","\n","#### Maximum Points: 100\n","\n","<div>\n","    <table>\n","        <tr><td><h3>Sr. no.</h3></td> <td><h3>Section</h3></td> <td><h3>Points</h3></td> </tr>\n","        <tr><td><h3>1</h3></td> <td><h3>1.1. Dataset Class</h3></td> <td><h3>7</h3></td> </tr>\n","        <tr><td><h3>2</h3></td> <td><h3>1.2. Visualize dataset</h3></td> <td><h3>3</h3></td> </tr>\n","        <tr><td><h3>3</h3></td> <td><h3>2. Evaluation Metrics</h3></td> <td><h3>10</h3></td> </tr>\n","        <tr><td><h3>4</h3></td> <td><h3>3. Model</h3></td> <td><h3>10</h3></td> </tr>\n","        <tr><td><h3>5</h3></td> <td><h3>4.1. Train</h3></td> <td><h3>7</h3></td> </tr>\n","        <tr><td><h3>6</h3></td> <td><h3>4.2. Inference</h3></td> <td><h3>3</h3></td> </tr>\n","        <tr><td><h3>7</h3></td> <td><h3>5. Prepare Submission CSV</h3></td><td><h3>10</h3></td> </tr>\n","        <tr><td><h3>8</h3></td> <td><h3>6. Kaggle Profile Link</h3></td> <td><h3>50</h3></td> </tr>\n","    </table>\n","</div>\n","\n","---\n","\n","**In this project, you have participated in the Kaggle competition, and also submit the notebook and othe code in the course lab.**\n","\n","**This Kaggle competition is a semantic segmentation challenge.**\n","\n","<h2>Dataset Description </h2>\n","<p>The dataset consists of 3,269 images in 12 classes (including background). All images were taken from drones in a variety of scales. Samples are shown below:\n","<img src=\"https://www.dropbox.com/scl/fi/pswwraz1cc9srd9d4hxm3/data_montage.jpg?rlkey=074v9mc32et70ijl0dz3y0rvs&dl=1\" width=\"800\" height=\"800\">\n","<p>The data was splitted into public train set and private test set which is used for evaluation of submissions. You can split public subset into train and validation sets yourself.\n","Images are named with a unique <code>ImageId</code>. </p>\n","<p> You should segment and classify the images in the test set.</p>\n","<p>The dataset consists of landscape images taken from drones in a variety of scales.</p>\n","\n","**The notebook is divided into sections. You have to write code, as mention in the section.  For other helper functions, you can write `.py` files and import them in the notebook. You have to submit the notebook along with `.py` files. Your submitted code must be runnable without any bug.**"]},{"cell_type":"markdown","metadata":{},"source":["# <font style=\"color:green\">1. Data Exploration</font>\n","\n","In this section, you have to write your custom dataset class and visualize a few images (max five images) and its mask."]},{"cell_type":"markdown","metadata":{},"source":["## <font style=\"color:green\">1.1. Dataset Class [7 Points]</font>\n","\n","**In this sub-section, write your custom dataset class.**\n","\n","\n","**Note that there are not separate validation data, so you will have to create your validation set by dividing train data into train and validation data. Usually, in practice, we do `80:20` ratio for train and validation, respectively.** \n","\n","**for example:**\n","\n","```\n","class SemSegDataset(Dataset):\n","    \"\"\" Generic Dataset class for semantic segmentation datasets.\n","\n","        Arguments:\n","            data_path (string): Path to the dataset folder.\n","            images_folder (string): Name of the folder containing the images (related to the data_path).\n","            masks_folder (string): Name of the folder containing the masks (related to the data_path).\n","            csv_path (string): train or test csv file name\n","            image_ids (list): List of images.\n","            train_val_test (string): 'train', 'val' or 'test'\n","            transforms (callable, optional): A function/transform that inputs a sample\n","                and returns its transformed version.\n","            class_names (list, optional): Names of the classes.\n","            \n","\n","        Dataset folder structure:\n","            Folder containing the dataset should look like:\n","            - data_path\n","            -- images_folder\n","            -- masks_folder\n","\n","            Names of images in the images_folder and masks_folder should be the same for same samples.\n","    \"\"\"\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# dataset class implementation\n","class SemSegDataset(Dataset):\n","    \"\"\" Generic Dataset class for semantic segmentation datasets.\n","\n","        Arguments:\n","            data_path (string): Path to the dataset folder.\n","            images_folder (string): Name of the folder containing the images (related to the data_path).\n","            masks_folder (string): Name of the folder containing the masks (related to the data_path).\n","            csv_path (string): train or test csv file name\n","            image_ids (list): List of images.\n","            train_val_test (string): 'train', 'val' or 'test'\n","            transforms (callable, optional): A function/transform that inputs a sample\n","                and returns its transformed version.\n","            class_names (list, optional): Names of the classes.\n","            num_classes (int): Number of classes in the dataset.\n","            dataset_url (string, optional): url to remote repository containing the dataset.\n","            dataset_folder (string, optional): Folder containing the dataset (related to the git repo).\n","\n","        Dataset folder structure:\n","            Folder containing the dataset should look like:\n","            - data_path\n","            -- images_folder\n","            -- masks_folder\n","\n","            Names of images in the images_folder and masks_folder should match the same sample.\n","\n","    \"\"\"\n","    def __init__(\n","        self,\n","        data_path,\n","        images_folder,\n","        masks_folder,\n","        csv_folder,\n","        image_ids,\n","        train_val_test,\n","        transforms=None,\n","        class_names=None,\n","        num_classes = None,\n","        dataset_url=None,\n","        dataset_folder=None\n","    ):\n","\n","        self.num_classes = num_classes\n","        self.transforms = transforms\n","        self.class_names = class_names\n","        # check whether dataset loading parameters exist\n","        if not os.path.isdir(data_path) and dataset_url is not None and dataset_folder is not None:\n","            # download CamVid dataset to the predefined directory\n","            download_git_folder(dataset_url, dataset_folder, data_path)\n","        # get the map of image-mask pairs\n","        self.dataset = init_semantic_segmentation_dataset(data_path, images_folder, masks_folder)\n","\n","    def get_num_classes(self):\n","        \"\"\"Get number of classes in the dataset\"\"\"\n","        return self.num_classes\n","\n","    def get_class_name(self, idx):\n","        \"\"\"\n","            Get a specific class name\n","\n","            Arguments:\n","                idx (int): index of specific class.\n","\n","            Returns:\n","                If class_names are available and idx < number of classes,\n","                returns a specific class name, else returns an empty string.\n","        \"\"\"\n","        class_name = \"\"\n","        if self.class_names is not None and idx < len(self.num_classes):\n","            class_name = self.class_names[idx]\n","        return class_name\n","\n","    # get dataset's length\n","    def __len__(self):\n","        return len(self.dataset)\n","\n","    # get item by index\n","    def __getitem__(self, idx):\n","        sample = {\n","            \"image\": cv2.imread(self.dataset[idx][\"image\"])[..., ::-1],\n","            \"mask\": cv2.imread(self.dataset[idx][\"mask\"], 0)\n","        }\n","        # apply transforms to a sample\n","        if self.transforms is not None:\n","            sample = self.transforms(**sample)\n","            sample[\"mask\"] = sample[\"mask\"].long()\n","        return sample"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["## <font style=\"color:green\">1.2. Visualize dataset [3 Points]</font>\n","\n","**In this sub-section,  you have to plot a few images and its mask.**\n","\n","**for example:**\n","\n","---\n","\n","<img src=\"https://www.learnopencv.com/wp-content/uploads/2020/04/c3-w12-data-sample.png\">\n","\n","---"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["# <font style=\"color:green\">2. Evaluation Metrics [10 Points]</font>\n","\n","<p>This competition is evaluated on the mean <a href='https://en.wikipedia.org/wiki/Sørensen–Dice_coefficient'>Dice coefficient</a\n",">. The Dice coefficient can be used to compare the pixel-wise agreement between a predicted segmentation and its corresponding ground truth. The formula is given by: </p>\n","\n","\n","$$DSC =  \\frac{2 |X \\cap Y|}{|X|+ |Y|}$$\n","$$ \\small \\mathrm{where}\\ X = Predicted\\ Set\\ of\\ Pixels,\\ \\ Y = Ground\\ Truth $$\n","The Dice coefficient is defined to be 1 when both X and Y are empty.\n","\n","**In this section, you have to implement the dice coefficient evaluation metric.**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["# <font style=\"color:green\">3. Model [10 Points]</font>\n","\n","**In this section, you have to define your model.**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["# <font style=\"color:green\">4. Train & Inference</font>\n","\n","- **In this section, you have to train the model and infer on sample data.**\n","\n","\n","- **You can write your trainer class in this section.**\n","\n","\n","- **If you are using any loss function other than PyTorch standard loss function, you have to define in this section.**\n","\n","\n","- **This section should also have optimizer and LR-schedular (if using) details.**\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["## <font style=\"color:green\">4.1. Train [7 Points]</font>\n","\n","**Write your training code in this sub-section.**\n","\n","\n","**This section must contain training plots (use matplotlib or share tensorboard.dev scalars logs).**\n","\n","**You must have to plot the following:**\n","- **train loss**\n","\n","\n","- **validation loss**\n","\n","\n","- **IoU for all twelve classes (0-11) and the mean IoU of all classes on validatin data.** \n","\n","**an example of matplotlib plot:**\n","\n","---\n","\n","<img src='https://www.learnopencv.com/wp-content/uploads/2020/04/c3-w12-train-loss.png'>\n","\n","---\n","\n","<img src='https://www.learnopencv.com/wp-content/uploads/2020/04/c3-w12-val-loss.png'>\n","\n","---\n","\n","<img src='https://www.learnopencv.com/wp-content/uploads/2020/04/c3-w12-mean_iou.png'>\n","\n","---\n","\n","<img src='https://www.learnopencv.com/wp-content/uploads/2020/04/c3-w12-iou-0.png'>\n","\n","---\n","\n","<center>*</center>\n","<center>*</center>\n","<center>*</center>\n","\n","---\n","\n","<img src='https://www.learnopencv.com/wp-content/uploads/2020/04/c3-w12-iou-11.png'>\n","\n","---\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["## <font style=\"color:green\">4.2. Inference [3 Points]</font>\n","\n","**Plot some sample inference in this sub-section.**\n","\n","**for example:**\n","\n","---\n","\n","<img src='https://www.learnopencv.com/wp-content/uploads/2020/04/c3-w12-sample-predtiction.png'>\n","\n","---\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["# <font style=\"color:green\">5. Prepare Submission CSV [10 Points]</font>\n","\n","**Write your code to prepare the submission CSV file.**\n","\n","\n","**Note that in the submission file, you have to write Encoded Pixels.**\n","\n","[Here is a blog to understand what is Encoded Pixels.](https://medium.com/analytics-vidhya/generating-masks-from-encoded-pixels-semantic-segmentation-18635e834ad0)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["# <font style=\"color:green\">6. Kaggle Profile Link [50 Points]</font>\n","\n","Share your Kaggle profile link here with us so that we can give points for the competition score. \n","\n","You should have a minimum IoU of `0.60` on the test data to get all points. If the IoU is less than `0.55`, you will not get any points for the section. \n","\n","**You must have to submit `submission.csv` (prediction for images in `test.csv`) in `Submit Predictions` tab in Kaggle to get any evaluation in this section.**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
